```table-of-contents
```

# Matrizes

> [!NOTE] Motivação
> Matrizes são, fundamentalmente, tabelas numéricas sobre as quais se definem certas operações algébricas, úteis para armazenar vários dados em um só elemento. Além disso, as matrizes se aplicam ao estudo dos sistemas lineares, bem como desempenham um papel decisivo no estudo das transformações lineares, as quais são justamente as funções estudadas na Álgebra Linear.

## Definição

Sejam $m, n \in \mathbb{N}^*$. Uma matriz (real) do tipo $m \times n$ (lê-se: $m$ por $n$) é uma "tabela" disposta em $m$ linhas e $n$ colunas. Denotamos os números reais que formam a $i$-ésima linha de uma matriz $A$ por $a_{i1},a_{i2},\ldots,a_{in}$ e sua $j$-ésima coluna por $a_{1j},a_{2j},\ldots,a_{mj}$. Assim, escrevemos:

$$
A = \begin{bmatrix}
a_{11} & \cdots & a_{1n} \\
\vdots & \ddots & \vdots \\
a_{m1} & \cdots & a_{mn}
\end{bmatrix}
$$

Chamamos de **entradas**, de uma matriz $A$, os reais $a_{ij}$ qua a compõem. Poderemos indicar uma matriz $A$ do tipo $m \times n$ com entradas $a_{ij}$ por:

$$
A = (a_{ij})_{m \times n}
$$

Ou, simplesmente, $A = (a_{ij})$.

> [!info] Nota
> As matrizes também podem ser representadas por parênteses. Além disso, em casos que $i \geq 10$ e/ou $j \geq 10$, para que não haja confusão na representação, pode-se utilizar uma vírgula para separar: $a_{i,j}$.

#### Exemplo 1:

As matrizes $A = (a_{ij})_{3 \times 2}$, em que $a_{ij} = i + j$, e $B = (b_{ij})_{2 \times 4}$, em que $b_{ij} = i^j$, são:

$$
A = \begin{bmatrix}
2 & 3 \\
3 & 4 \\
4 & 5
\end{bmatrix}
\quad \text{e} \quad
B = \begin{bmatrix}
1 & 1 & 1 & 1 \\
2 & 4 & 8 & 16
\end{bmatrix}
$$

## Matriz Quadrada

Uma matriz $A$ do tipo $n \times n$ é dita quadrada de ordem $n$. O conjunto formado por suas entradas $a_{ii}$ é chamado de **diagonal** (ou **diagonal principal**) de $A$. O conjunto formado pelas entradas $a_{ij}$ tais que $i + j = n + 1$ é chamado de **diagonal secundária** de $A$.

> [!important] Observação
> Quando uma matriz não é quadrada ela possui tipo; quando ela é quadrada ela possui ordem, que é uma forma de "abreviar" o tipo para que não seja necessário repetir o número.

#### Exemplo 2:

Dada a matriz $A$ quadrada de ordem $3$ abaixo, sua diagonal é formada pelos números $2$, $4$ e $1$. A diagonal secundária é formada por $1$, $4$ e $4$.

$$
A = \begin{bmatrix}
2 & 3 & 1 \\
3 & 4 & 0 \\
4 & 5 & 1 \\
\end{bmatrix}
$$

## Matriz Nula

Uma matriz do tipo $m \times n$ cujas entradas são todas iguais a zero chama-se **nula** e será denotada por $0_{m \times n}$.

> Note que, para que não haja confusão, deve-se apresentar a matriz nula explicitando o seu tipo.

# Operações com Matrizes

## Produto Por Escalar e Adição de Matrizes

Dadas matrizes de mesmo tempo, $A = (a_{ij})_{m \times n}$ e $B = (b_{ij})_{m \times n}$, e $\lambda \in \mathbb{R}$, definimos o **produto por escalar $\lambda \cdot A$** e a **adição $A + B$** por:

$$
\lambda \cdot A = \begin{bmatrix}
\lambda \cdot a_{11} & \cdots & \lambda \cdot a_{1n} \\
\vdots & \ddots & \vdots \\
\lambda \cdot a_{m1} & \cdots & \lambda \cdot a_{mn}
\end{bmatrix}
\quad \text{e} \quad
A + B = \begin{bmatrix}
a_{11} + b_{11} & \cdots & a_{1n} + b_{1n} \\
\vdots & \ddots & \vdots \\
a_{m1} + b_{m1} & \cdots & a_{mn} + b_{mn}
\end{bmatrix}
$$

### Propriedades

Sejam $A$, $B$ e $C$ matrizes de mesmo tipo $m \times n$, e $\lambda, \mu \in \mathbb{R}$. Tem-se:

**Adição:**

- Comutatividade: $A + B = B + A$
- Associatividade: $A + (B + C) = (A + B) + C$
- Elemento neutro: $A + 0_{m \times n} = A$
- Existência do oposto aditivo: $A + (-A) = 0_{m \times n}$

**Multiplicação por escalar:**

- Associatividade: $\lambda(\mu A) = (\lambda\mu)A$
- Elemento neutro: $1 \cdot A = A$
- Distributividade, de uma em relação à outra:
	- $\lambda(A + B) = \lambda A + \lambda B$
	- $(\lambda + \mu)A = \lambda A + \mu A$

#### Exemplo 3:

Calcule:

$$
A = 3 \cdot \begin{bmatrix}
2 & 3 \\
3 & 4 \\
4 & 5
\end{bmatrix}
\quad \text{e} \quad
B = \begin{bmatrix}
1 & 1 & 1 & 1 \\
2 & 4 & 8 & 16
\end{bmatrix}
+
\begin{bmatrix}
1 & 2 & 3 & 4 \\
1 & 4 & 9 & 16
\end{bmatrix}
$$

Teremos:

$$
A = \begin{bmatrix}
6 & 9 \\
9 & 12 \\
12 & 15
\end{bmatrix}
\quad \text{e} \quad
B = \begin{bmatrix}
2 & 3 & 4 & 5 \\
3 & 8 & 17 & 32
\end{bmatrix}
$$

## Multiplicação de Matrizes

Dadas matrizes $A = (a_{ij})_{m \times n}$ e $B = (b_{ij})_{n \times p}$, onde o número de colunas de $A$ coincide com o número de linhas de $B$. Definimos o **produto $AB$** como a matriz $P = (p_{ij})_{m \times p}$, cujas entradas são:

$$
p_{ij} = \sum_{k = 1}^n a_{ik}b_{kj} = a_{i1}b_{1j} + a_{i2}b_{2j} + \cdots + a_{in}b_{nj}
$$

#### Exemplo 4:

Calcule:

$$
A = \begin{bmatrix}
2 & 3 \\
3 & 4 \\
4 & 5
\end{bmatrix}
\cdot
\begin{bmatrix}
0 & -1 & 3 \\
3 & 2 & 1
\end{bmatrix}
$$

Teremos:

$$
A = \begin{bmatrix}
9 & 4 & 9 \\
12 & 5 & 13 \\
15 & 6 & 17
\end{bmatrix}
$$

### Propriedades

Sejam as matrizes $A = (a_{ij})_{m \times n}$, $B = (b_{ij})_{n \times p}$, $C = (c_{ij})_{p \times 1}$, $D = (d_{ij})_{n \times p}$ e $E = (e_{ij})_{m \times n}$. Tem-se:

- Associatividade: $A(BC) = (AB)C$
- Distributividade à esquerda, em relação à soma: $A(B + D) = AB + AD$
- Distributividade à direita, em relação à soma: $(A + E)B = AB + EB$

> [!warning] Observação
> Dadas duas matrizes $A$ e $B$ quadradas e de mesma ordem, os dois produtos $AB$ e $BA$ estão bem definidos. No entanto, de modo geral, eles **não são iguais**, isto é, **o produto de matrizes quadradas de mesma ordem não é comutativo**. Quando, excepcionalmente, ocorre a igualdade $AB = BA$, dizemos que $A$ e $B$ **comutam**.

# Sistemas Lineares e Matrizes

Um sistema de $m$ equações lineares nas variáveis $x_1,x_2,\ldots,x_n$ pode ser representado pelas equações:

$$
\displaylines{
\left\{
\begin{array}{l}
a_{11} x_1 + a_{12} x_2 + \cdots + a_{1n} x_n = b_1 \\
a_{21} x_1 + a_{22} x_2 + \cdots + a_{2n} x_n = b_2 \\
\vdots \\
a_{m1} x_1 + a_{m2} x_2 + \cdots + a_{mn} x_n = b_m \\
\end{array}
\right.
}
$$

Tal sistema é equivalente à equação matricial $AX = B$, onde:

$$
A = \begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix} \quad , \quad
X = \begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{bmatrix} \quad \text{e} \quad
B = \begin{bmatrix}
b_1 \\
b_2 \\
\vdots \\
b_m
\end{bmatrix}
$$

Nesse caso, dizemos que $A$ é a **matriz do sistema**. Quando $B = 0_{m \times n}$, o sistema é dito **homogêneo**. Observe que todo sistema homogêneo admite a solução $X = 0_{n \times 1}$, dita **trivial**.

## Sistemas Lineares Equivalentes

Dois sistemas lineares são ditos **equivalentes** quando ambos têm o mesmo conjunto solução.

## Matriz Aumentada de um Sistema Linear

Dado um sistema linear $AX = B$, define-se a sua **matriz aumentada ($A|B$)** como sendo a matriz obtida "posicionando" a matriz $B$ à direita da matriz $A$, isto é:

$$
(A|B) = \begin{bmatrix}
a_{11} & \cdots & a_{1n} & b_1 \\
\vdots & \ddots & \vdots & \vdots \\
a_{m1} & \cdots & a_{mn} & b_m
\end{bmatrix}
$$

#### Exemplo 5:

Qual a matriz aumentada do sistema linear abaixo?

$$
\displaylines{
\left\{
\begin{array}{l}
& x & + & y & - & z & = & 1 \\
& x & - & y & & & = & 1
\end{array}
\right.
}
$$

Vamos primeiro montar a matriz do sistema, dada por $A$:

$$
A = \begin{bmatrix}
1 & 1 & -1 \\
1 & -1 & 0
\end{bmatrix}
$$

Agora, a matriz $B$:

$$
B = \begin{bmatrix}
1 \\
1
\end{bmatrix}
$$

Por fim, teremos a matriz aumentada de $A$, dada por $(A|B)$:

$$
(A|B) = \begin{bmatrix}
1 & 1 & -1 & 1 \\
1 & -1 & 0 & 1
\end{bmatrix}
$$

# Operações Elementares sobre Matrizes

Algumas operações sobre as linhas de uma matriz são ditas **elementares**. São elas:

- $(l_i \leftrightarrow l_j)$: troca de posição entre duas linhas $l_i$ e $l_j$;
- $(l_i \to \lambda l_i)$: multiplicação de uma linha $l_i$ por um escalar $\lambda \neq 0$;
- $(l_j \to l_j + \lambda l_i)$: substituição de uma linha $l_j$ por $l_j + \lambda l_i$, sendo $\lambda \neq 0$.

## Equivalência por Linhas

Diz-se que uma matriz $B$ é **linha equivalente** a uma matriz $A$ quando $B$ é obtida de $A$ efetuando-se nesta uma sequência de operações elementares.

Dois sistemas lineares $AX = B$ e $A'X = B'$ são equivalentes se suas matrizes aumentadas $(A|B)$ e $(A'|B')$ são linha equivalentes.

## Matriz Escalonada

Diz-se que uma matriz $A = (a_{ij})_{m \times n}$ é **escalonada** quando cumpre as seguintes condições:

- O primeiro elemento não-nulo de uma linha está à esquerda do primeiro elemento não-nulo da linha subsequentes;
- As linhas nulas, caso existam, estão abaixo das demais.

Para resolvermos um sistema linear, fazemos o **escalonamento** da matriz aumentada do sistema a fim de obtermos uma matriz escalonada que seja linha equivalente à matriz aumentada do sistema. Esse procedimento é chamado de **Método de Gauss** ou **Eliminação Gaussiana**.

#### Exemplo 6:

Encontre o conjunto solução para o sistema abaixo.

$$
\displaylines{
\left\{
\begin{array}{l}
x - 2y + 3z = 1 \\
2x + y - z = 2 \\
4x - 3y + 5z = 4
\end{array}
\right.
}
$$

Vamos montar a matriz aumentada do sistema:

$$
(A|B) = \begin{bmatrix}
1 & -2 & 3 & 1 \\
2 & 1 & -1 & 2 \\
4 & -3 & 5 & 4
\end{bmatrix}
$$

Agora, escalonemos ela:

$$
\displaylines{
\begin{align*}
\begin{bmatrix}
1 & -2 & 3 & 1 \\
2 & 1 & -1 & 2 \\
4 & -3 & 5 & 4
\end{bmatrix}
&\xrightarrow{l_2 \to l_2 - 2l_1} \begin{bmatrix}
1 & -2 & 3 & 1 \\
0 & 5 & -7 & 0 \\
4 & -3 & 5 & 4
\end{bmatrix} \\
&\xrightarrow{l_3 \to l_3 - 4l_1} \begin{bmatrix}
1 & -2 & 3 & 1 \\
0 & 5 & -7 & 0 \\
0 & 5 & -7 & 0
\end{bmatrix} \\
&\xrightarrow{l_3 \to l_3 - l_2} \begin{bmatrix}
1 & -2 & 3 & 1 \\
0 & 5 & -7 & 0 \\
0 & 0 & 0 & 0
\end{bmatrix}
\end{align*}
}
$$

Logo, a solução do sistema será:

$$
5y - 7z = 0 \iff y = \frac{7z}{5}
$$

E, assim:

$$
x - 2y + 3z = 1 \iff x - 2 \cdot \frac{7z}{5} + 3z = 1 \iff x = -\frac{z}{5} + 1
$$

Portanto, $(-\frac{z}{5} + 1, \frac{7z}{5}, z)$, onde $z \in \mathbb{R}$, é a solução do sistema.

# Tipos de Matrizes Quadradas

## Matrizes Triangulares e Diagonais

Uma matriz quadrada $A = (a_{ij})_{n \times n}$ é dita **triangular** quando ocorre uma das possibilidades:

$$
a_{ij} = 0 \quad \forall i > j \quad \text{ou} \quad a_{ij} = 0 \quad \forall i < j
$$

No primeiro caso, ela é dita **triangular superior** e no segundo, **triangular inferior**. Uma matriz que é triangular superior e inferior é dita **diagonal**.

> [!tip] Dica
> **Triangular superior:** todas as entradas *abaixo* da diagonal principal são iguais a zero (as entradas acima não obrigatoriamente são nulas).
> **Triangular inferior:** todas as entradas *acima* da diagonal principal são iguais a zero (as entradas abaixo não obrigatoriamente são nulas).

#### Exemplo 7:

As matrizes $A$, $B$ e $C$ abaixo são, respectivamente, triangular superior, inferior e diagonal.

$$
A = \begin{bmatrix}
3 & 0 & 2 \\
0 & 0 & 1 \\
0 & 0 & 1
\end{bmatrix} \quad , \quad
B = \begin{bmatrix}
1 & 0 & 0 \\
7 & 2 & 0 \\
-2 & 0 & 0
\end{bmatrix} \quad \text{e} \quad
C = \begin{bmatrix}
1 & 0 \\
0 & 2
\end{bmatrix}
$$

## Matriz Identidade

Uma matriz diagonal $n \times n$ cujas entradas não obrigatoriamente nulas são todas iguais a $1$ é chamada de **matriz identidade** de ordem $n$, a qual denota-se por $I_n$ ou, simplesmente, por $I$.

A matriz identidade de ordem $n$ é o elemento neutro da multiplicação de matrizes quadradas, pois, para toda matriz quadrada $A$ de ordem $n$, vale a igualdade:

$$
AI = IA = A
$$

Além disso, dada uma matriz $B_{n \times m}$, vale também:

$$
B I_m = I_n B = B
$$

## Matrizes Invertíveis

Diz-se que uma matriz quadrada $A$ é **invertível**, quando existe uma matriz quadrada $B$, de mesma ordem que $A$, tal que:

$$
AB = BA = I
$$

Prova-se que $A$, quando invertível, possui uma única matriz inversa. Tal matriz é dita a **inversa** de $A$ e é denotada por $A^{-1}$.

Para calcular a inversa de uma matriz $A$, escalona-se a matriz aumentada $(A|I)$, a fim de se obter uma matriz equivalente por linhas do tipo $(I|B)$. Se for possível tal procedimento, então $B = A^{-1}$. Caso contrário, $A$ não é invertível.

#### Exemplo 8:

Verifique que as matrizes abaixo são invertíveis multiplicando-as.

$$
A = \begin{bmatrix}
1 & 0 \\
0 & \frac{1}{2}
\end{bmatrix} \quad \text{e} \quad
B = \begin{bmatrix}
1 & 0 \\
0 & 2
\end{bmatrix}
$$

Teremos:

$$
AB = \begin{bmatrix}
1 & 0 \\
0 & \frac{1}{2}
\end{bmatrix} \cdot \begin{bmatrix}
1 & 0 \\
0 & 2
\end{bmatrix} = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}
$$

$$
BA = \begin{bmatrix}
1 & 0 \\
0 & 2
\end{bmatrix} \cdot \begin{bmatrix}
1 & 0 \\
0 & \frac{1}{2}
\end{bmatrix} = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}
$$

Logo, segue que $A$ e $B$ são invertíveis.

#### Exemplo 9:

Calcule a inversa das matrizes abaixo:

$$
A = \begin{bmatrix}
1 & 1 \\
0 & 2
\end{bmatrix} \quad \text{e} \quad
B = \begin{bmatrix}
1 & 2 & 1 \\
0 & 1 & 1 \\
2 & 4 & 2
\end{bmatrix}
$$

Escalonemos $(A|I)$:

$$
\displaylines{
\begin{align*}
\left[
\begin{array}{cc|cc}
1 & 1 & 1 & 0 \\
0 & 2 & 0 & 1
\end{array}
\right]
&\xrightarrow{l_2 \to \frac{l_2}{2}} \left[
\begin{array}{cc|cc}
1 & 1 & 1 & 0 \\
0 & 1 & 0 & \frac{1}{2}
\end{array}
\right] \\
&\xrightarrow{l_1 \to l_1 - l_2} \left[
\begin{array}{cc|cc}
1 & 0 & 1 & -\frac{1}{2} \\
0 & 1 & 0 & \frac{1}{2}
\end{array}
\right] \\
\end{align*}
}
$$

Logo, $A$ é invertível e a $A^{-1} = \begin{bmatrix} 1 & -\frac{1}{2} \\ 0 & \frac{1}{2} \end{bmatrix}$.

Agora, escalonemos $(B|I)$:

$$
\displaylines{
\begin{align*}
\left[
\begin{array}{ccc|ccc}
1 & 2 & 1 & 1 & 0 & 0 \\
0 & 1 & 1 & 0 & 1 & 0\\
2 & 4 & 2 & 0 & 0 & 1
\end{array}
\right]
&\xrightarrow{l_3 \to l_3 - 2l_1} \left[
\begin{array}{ccc|ccc}
1 & 2 & 1 & 1 & 0 & 0 \\
0 & 1 & 1 & 0 & 1 & 0\\
0 & 0 & 0 & -2 & 0 & 1
\end{array}
\right]
\end{align*}
}
$$

Como não é possível obter uma matriz do tipo $[I|C]$, então $B$ não é invertível.

#### Exemplo 10:

Qual a solução do sistema abaixo?

$$
\displaylines{
\left\{
\begin{array}{l}
x + y = 2 \\
2y = 4
\end{array}
\right.
}
$$

Note que temos o sistema $AX = B$, onde:

- $A = \begin{bmatrix} 1 & 1 \\ 0 & 2 \end{bmatrix}$ (exemplo 9)
- $B = \begin{bmatrix} 2 \\ 4 \end{bmatrix}$

Segue:

$$
\displaylines{
\begin{align*}
AX = B
&\iff A^{-1}AX = A^{-1}B \\
&\iff IX = A^{-1}B \\
&\iff X = A^{-1}B = \begin{bmatrix} 1 & -\frac{1}{2} \\ 0 & \frac{1}{2} \end{bmatrix} \begin{bmatrix} 2 \\ 4 \end{bmatrix} = \begin{bmatrix} 0 \\ 2 \end{bmatrix}
\end{align*}
}
$$

Logo, $x = 0$ e $y = 2$ é a solução do sistema.

# Determinante de Matrizes $2 \times 2$ e $3 \times 3$

Dadas as matrizes $A = (a_{ij})_{2 \times 2}$ e $B = (b_{ij})_{3 \times 3}$, definimos os **determinantes** de $A$ e de $B$, denotados, respectivamente, por $\det(A)$ e $\det(B)$, como sendo:

$$
\displaylines{
\det(A) = \begin{vmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{vmatrix} = a_{11}a_{22} - a_{12}a_{21} \\
\text{e} \\
\det(B) = \begin{vmatrix}
b_{11} & b_{12} & b_{13} \\
b_{21} & b_{22} & b_{23} \\
b_{31} & b_{32} & b_{33}
\end{vmatrix} = (b_{11}b_{22}b_{33} + b_{12}b_{23}b_{31} + b_{13}b_{21}b_{32}) - (b_{13}b_{22}b_{31} + b_{11}b_{23}b_{32} + b_{12}b_{21}b_{33})
}
$$
